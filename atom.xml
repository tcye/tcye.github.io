<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tiancai&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://tcye.github.io/"/>
  <updated>2019-10-17T07:07:02.973Z</updated>
  <id>http://tcye.github.io/</id>
  
  <author>
    <name>Tiancai Ye</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>闲想人生</title>
    <link href="http://tcye.github.io/posts/2d9e8f91/"/>
    <id>http://tcye.github.io/posts/2d9e8f91/</id>
    <published>2019-10-17T07:07:02.973Z</published>
    <updated>2019-10-17T07:07:02.973Z</updated>
    
    <content type="html"><![CDATA[<p>最近很忙，老婆怀孕需要照顾，新的工作需要熟悉铺开，整个人都处于一种疲于奔命的感觉。所谓的闲想，也只是在深夜独处时，这暂时的宁静，让我有点“悠闲自得”的感觉。现在是凌晨6:30，可能有些人已经起床，有些人比如我，还没睡。刚改完了一些代码，还不想睡(可能因为自己太珍惜这独处时光了)，那就在这思考思考。</p><h3 id="关于责任"><a href="#关于责任" class="headerlink" title="关于责任"></a>关于责任</h3><p>小时候总觉得父母给的不够，似乎没有那么多关心，没有那么多问候，现在才明白，爸妈他们已经做的很好了。因为对自己好，是一种本能，对别人好，是一种选择，而选择常常是困难的。工作三年多了，也开始了很多角色的转变，这其中最大的本质区别，就是责任越来越大。父母需要负责，老婆孩子需要负责，似乎现在负担最小的是对自己负责，哈哈。不过话又说回来，这并不是件坏事，我觉得这才是真正的成长。现在很多人不婚，不生养后代，其实就是在逃避责任而已，毕竟不需要对其他人负责的人生，是看似更加轻松愉悦的。然而，“不知道所有命运赠送的礼物，早已在暗中标好了价格”。</p><h3 id="关于理想"><a href="#关于理想" class="headerlink" title="关于理想"></a>关于理想</h3><p>上学时，总有大理想，工作后，则很少谈及理想这个词。有人说，这是因为学生时代，人总是太轻狂，而步入社会后，收到一翻磨砺，才知道脚踏实地。我觉得有点道理，但不全对。学生时代有各种各样的可塑性，确实可能无限，就好比股票一样，有想象空间比实际盈利更重要。而工作后，每个人都会被日趋分化，可塑性逐渐降低，专业性逐渐升高。在这个过程中，每个人的理想也会更加明确。不提理想，因为现实太残酷，大多数人会发现，能力匹配不上理想。</p><h3 id="关于善良"><a href="#关于善良" class="headerlink" title="关于善良"></a>关于善良</h3><p>最近公司员工大会，小龙说，善良比聪明更重要。小龙说的是产品的建设，而我想，这大概也适用在人身上。因为聪明是一种天赋，而善良是一种选择，而且，我觉得大智和大善是殊途同归的，大智的人，必然善良。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近很忙，老婆怀孕需要照顾，新的工作需要熟悉铺开，整个人都处于一种疲于奔命的感觉。所谓的闲想，也只是在深夜独处时，这暂时的宁静，让我有点“悠闲自得”的感觉。现在是凌晨6:30，可能有些人已经起床，有些人比如我，还没睡。刚改完了一些代码，还不想睡(可能因为自己太珍惜这独处时光
      
    
    </summary>
    
      <category term="life" scheme="http://tcye.github.io/categories/life/"/>
    
    
  </entry>
  
  <entry>
    <title>假期计划</title>
    <link href="http://tcye.github.io/posts/b37321a2/"/>
    <id>http://tcye.github.io/posts/b37321a2/</id>
    <published>2018-09-11T02:16:17.000Z</published>
    <updated>2019-10-17T07:07:02.973Z</updated>
    
    <content type="html"><![CDATA[<p>上周从BIGO离职了，下一站微信。离职原因暂且不表，只是这段时间得把去年未休完的9天年假休了，所以也就难得这段清闲时光。然而我是个坐不住的人，让我出去玩吧，总觉得一个人也没啥意思，在家待着吧，总得找点事做。所以，看看书，写写博客，把以前看过的资料、论文、代码，重新加以总结和思考，或许能让我这接近两周的gap更加充实一些。</p><p>计划如下：</p><ol><li><p>重新看一遍西瓜书。虽然现在视觉任务都用深度学习了，但是传统的机器学习的很多思想还是很重要，具有启发性的。譬如，我们曾经用深度学习预测一段短视频是否是未成年人，然而深度模型都是针对单帧图像做的，那么视频中如何做呢？比较简单的有加权平均、投票等方法，显然，这些方法都很trival，且同样有阈值选取等问题。最后，我们用xgboost综合多帧结果，效果提升了接近8个百分点。显然，这需要有传统机器学习的背景才能想到这些方法。因此，趁着这个gap看看西瓜书，重点看看树模型和聚类等非监督算法，看看对平时的工作是否能有些启发。</p></li><li><p>重新看一遍cs231n。其实深度学习在视觉上的应用，本人做过分类、目标检测、关键点预测，基本对视觉类的任务都有个大致了解。然而，自己始终有个盲区，就是rnn类似的工作从未接触过，因而在实际工作中，解决问题的思路也会受限，常常会去避免使用rnn的方法。虽然实际工作中，rnn并非表现良好的方法，但作为一个盲区，还是得补一补功课，有助于以后解决问题的思路开阔点。</p></li><li><p>锻炼身体。工作后，就很少运动，肚子上的肉也渐渐多了起来，最主要的是，常常感觉精神不佳。这段时间有空每晚去儿童公园跑跑步，恢复下体能吧。</p></li></ol><p>就这些，其它就吃好喝好，为下一份工作攒足精力！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;上周从BIGO离职了，下一站微信。离职原因暂且不表，只是这段时间得把去年未休完的9天
年假休了，所以也就难得这段清闲时光。然而我是个坐不住的人，让我出去玩吧，总觉得一
个人也没啥意思，在家待着吧，总得找点事做。所以，看看书，写写博客，把以前看过的资料、
论文、代码，重新加以
      
    
    </summary>
    
      <category term="life" scheme="http://tcye.github.io/categories/life/"/>
    
    
  </entry>
  
  <entry>
    <title>如何识别一个优秀的算法工程师</title>
    <link href="http://tcye.github.io/posts/5129a7c0/"/>
    <id>http://tcye.github.io/posts/5129a7c0/</id>
    <published>2018-09-10T16:31:17.000Z</published>
    <updated>2019-10-17T07:07:02.973Z</updated>
    
    <content type="html"><![CDATA[<p>在BIGO工作期间，面试了不少求职者，有应届毕业生，也有工作了好几年的，当然，有时候也有像我一样，从其他领域转来做深度学习的同学。面试完后，对于一些同学，面试官之前常常有争议，有的觉得挺不错的，其他面试官觉得一定不能要。所以，在面试了很多次后，我自己也常常想，什么样的同学是企业所需要的，如何识别其中优秀的同学，又如何识别那些夸夸其谈之辈呢？</p><p>个人觉得，一个优秀的算法工程师，有以下气味：</p><h2 id="代码能力很强"><a href="#代码能力很强" class="headerlink" title="代码能力很强"></a>代码能力很强</h2><p>这个是我觉得最为重要的能力。常常遇到一些对各种模型paper了如指掌，从faster rcnn系列到ssd, yolo，无所不知，然而让他写一个计算iou的代码就傻眼的同学。在我看来，这些同学只是调包侠而以，在求职市场上是最低级的存在。有些同学也许会反驳我，一些博士代码能力也一般，可是数学好，做模型强啊。恰恰相反，我认识的一些真正的牛博中，没有一个不是代码能力强悍的，可以想象，他们那些精巧的模型，没有强悍的代码能力做支持，是如何开创性的实现出来并发paper的？所以，纸上谈兵谁都会，show me the code。</p><h2 id="真正理解算法，而不是只会推导公式"><a href="#真正理解算法，而不是只会推导公式" class="headerlink" title="真正理解算法，而不是只会推导公式"></a>真正理解算法，而不是只会推导公式</h2><p>我面试时，很少让人直接去推导个什么公式（当然，各种线性模型我还是会考察的，这是基本的线性代数能力），但是我会去考察其形象理解能力。譬如，我常常看到有同学简历里写到会svm，于是我会问他们，svm和逻辑斯特回归，当数据类别严重不均衡时，应该选择哪个更好呢？这个问题不需要会推导求解公式，然而却能真正考察面试者是否真正理解svm的出发点，如果这个问题回答不出来，我认为，即使是会推导svm的求解公式，也是比较差的候选人。</p><h2 id="学习意愿强，不挑活"><a href="#学习意愿强，不挑活" class="headerlink" title="学习意愿强，不挑活"></a>学习意愿强，不挑活</h2><p>算法工程师之所以叫算法工程师，是因为他们常常会遇到未知的问题，学习并尝试解决它，所以，学习意愿不够强的人，不能要，知识储备再高，也会遇到未知难题。挑活的，也不能要，实际工作中，从找数据到清洗数据，这都是落地算法的必经之路，没有人能有特权只选择自己想干的，把脏活累活丢给别人。</p><p>实际面试中，面试10个人，能有2个人能达到上述要求就不错了。所以，之前在知乎看到一个讨论，说2019的校招深度学习岗位竞争是否很激烈，我想说，其实觉得激烈的，大多是那些看着这行有热钱，网上随便看了看视频就来面试的，对于真正在这行有能力的同学，一点都不激烈，是被各个公司抢着要的。而且，经过这么久，团队从无建立，各个公司也明白了，其实算法团队招人重在质量，而非数量，招10个混混，不如一个大神，算法领域确实如此。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在BIGO工作期间，面试了不少求职者，有应届毕业生，也有工作了好几年的，当然，有时候
也有像我一样，从其他领域转来做深度学习的同学。面试完后，对于一些同学，面试官之前
常常有争议，有的觉得挺不错的，其他面试官觉得一定不能要。所以，在面试了很多次后，
我自己也常常想，什么样的
      
    
    </summary>
    
      <category term="life" scheme="http://tcye.github.io/categories/life/"/>
    
    
  </entry>
  
  <entry>
    <title>减小模型大小的一些设计思路</title>
    <link href="http://tcye.github.io/posts/cfaa02c9/"/>
    <id>http://tcye.github.io/posts/cfaa02c9/</id>
    <published>2018-01-15T10:00:00.000Z</published>
    <updated>2019-10-17T07:07:02.973Z</updated>
    
    <content type="html"><![CDATA[<h2 id="暴力channel维度的缩减"><a href="#暴力channel维度的缩减" class="headerlink" title="暴力channel维度的缩减"></a>暴力channel维度的缩减</h2><p>将layer的输入输出在原网络结构上按相同比例缩减。例如nsfw就是在resnet-50的基础上缩减而来的。</p><h2 id="bottlenect结构"><a href="#bottlenect结构" class="headerlink" title="bottlenect结构"></a>bottlenect结构</h2><p>使用1x1的卷积核对原输入降维后，再进行大卷积核的卷积计算。</p><h2 id="group卷积"><a href="#group卷积" class="headerlink" title="group卷积"></a>group卷积</h2><p>分组卷积先按channel分为多个group，每个group内分别做卷积，group的输出再concat，最后使用1x1的卷积把所有group信息综合起来。（resnext思想，shufflenet进行了改进）</p><h2 id="depthwise卷积"><a href="#depthwise卷积" class="headerlink" title="depthwise卷积"></a>depthwise卷积</h2><p>group卷积的特例，group数量等于输入channel数量，即分别对每个channel做卷积，不考虑channel之间的相关性，然后再由1x1的卷积获取跨通道之间相关性的联系。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;暴力channel维度的缩减&quot;&gt;&lt;a href=&quot;#暴力channel维度的缩减&quot; class=&quot;headerlink&quot; title=&quot;暴力channel维度的缩减&quot;&gt;&lt;/a&gt;暴力channel维度的缩减&lt;/h2&gt;&lt;p&gt;将layer的输入输出在原网络结构上按相同比
      
    
    </summary>
    
      <category term="machine-learning" scheme="http://tcye.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>CNN卷积神经网络架构总结</title>
    <link href="http://tcye.github.io/posts/8b256d5e/"/>
    <id>http://tcye.github.io/posts/8b256d5e/</id>
    <published>2017-09-29T05:30:35.000Z</published>
    <updated>2019-10-17T07:07:02.973Z</updated>
    
    <content type="html"><![CDATA[<p><strong>注：本文将会以论文读后笔记的形式呈现，后续不断补充占坑</strong></p><h2 id="An-Analysis-Of-Deep-Neural-Network-Models-For-Practical-Applications"><a href="#An-Analysis-Of-Deep-Neural-Network-Models-For-Practical-Applications" class="headerlink" title="An Analysis Of Deep Neural Network Models For Practical Applications"></a>An Analysis Of Deep Neural Network Models For Practical Applications</h2><p>在此综述下总结下2015年前的主流CNN架构及其贡献</p><ol><li>LeNet5(1998):<ul><li>CNN三特性: 局部感知、下采样、权值共享</li><li>采用三层架构：卷积、下采样、非线性激活函数(tanh, sigmoid)，多层神经网络(MLP)作为最后的分类器</li><li>后续的CNN架构大多基于LeNet5的这些特性，然而由于当时硬件计算能力限制，后续很长时间神经网络没有发展</li></ul></li><li>AlexNet(2012): 赢的2012ImageNet冠军，从LeNet5的5层增加到7层<ul><li>使用ReLU作为激活函数，降低计算量</li><li>引入Dropout防止过拟合</li><li>引入Max-Pooling技术</li><li>使用双GPU，分group卷积，显著减少训练时间<a id="more"></a></li></ul></li><li>Network In Network(2013):<ul><li>首次提出在卷积层后再紧跟一个1x1的卷积核对特征进行融合，有效合并卷积特征，减少网络参数</li><li>违背了LeNet在浅层使用大卷积核的设计原则，但取得了良好效果</li></ul></li><li>VGG(2014):<ul><li>相比AlexNet使用9x9,11x11这样的大卷积核，VGG使用连续的3x3卷积核，可以获得同样的感受野，而参数数量和计算量可以显著减少</li></ul></li><li>GoogleNet(2014):<ul><li>提出了Inception局部网络，并通过堆积Inception这样的局部小网络组成大网络</li><li>类似NiN，使用了1x1的卷积核大幅减少参数数量和计算，即现在的流行的bottlenect layer</li><li>Bottlenect Layer: 先使用1x1卷积减少特征channel数量，再进行卷积，最后再用1x1卷积恢复特征数量，成功的原因是输入特征是相关的，可以适当的用1x1卷积去除冗余</li></ul></li><li>Inception V3(2015):<ul><li>提出Batch-Normalization，对层的输入进行归一化，有助于训练</li></ul></li></ol><p>最后，使用论文中的一张神图结束这篇论文的笔记，准确率-时间复杂度-参数数量都在下图中很好的呈现了。<img src="/images/acc_vs_net_vs_ops.png" alt="acc-ops"></p><p>2015年前的架构及贡献大致如此，目前更多的都是基于ResNet思想的架构，采用Identity-Map的结构，利于训练超深卷积神经网络</p><h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><p>增加神经网络的宽度有助于于记忆，深度有助于推理。人们发现增加神经网络的深度可以提升效果，但是网络越深，梯度消失的现象越明显，使得网络越发难以训练好。Resnet解决的问题就是，如何在加深网络的情况下，又能解决梯度消失的问题。Renset引入了残差网络来解决这一问题。进一步分析，实际上Resnet相当于一个多人投票系统，具体分析可见<a href="http://blog.csdn.net/buyi_shizi/article/details/53336192" target="_blank" rel="noopener">对Resnet的理解</a></p><h2 id="Wide-ResNet"><a href="#Wide-ResNet" class="headerlink" title="Wide ResNet"></a>Wide ResNet</h2><p>增加模型宽度（即简单的扩大output channel的数量）有助于提升模型效果。提供了另外一个思路，但效果有限。</p><h2 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h2><h2 id="Dual-Path-Networks-DPNs"><a href="#Dual-Path-Networks-DPNs" class="headerlink" title="Dual Path Networks (DPNs)"></a>Dual Path Networks (DPNs)</h2><h2 id="Squeeze-and-Excitation-Networks-SENet"><a href="#Squeeze-and-Excitation-Networks-SENet" class="headerlink" title="Squeeze-and-Excitation Networks (SENet)"></a>Squeeze-and-Excitation Networks (SENet)</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;注：本文将会以论文读后笔记的形式呈现，后续不断补充占坑&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;An-Analysis-Of-Deep-Neural-Network-Models-For-Practical-Applications&quot;&gt;&lt;a href=&quot;#An-Analysis-Of-Deep-Neural-Network-Models-For-Practical-Applications&quot; class=&quot;headerlink&quot; title=&quot;An Analysis Of Deep Neural Network Models For Practical Applications&quot;&gt;&lt;/a&gt;An Analysis Of Deep Neural Network Models For Practical Applications&lt;/h2&gt;&lt;p&gt;在此综述下总结下2015年前的主流CNN架构及其贡献&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;LeNet5(1998):&lt;ul&gt;
&lt;li&gt;CNN三特性: 局部感知、下采样、权值共享&lt;/li&gt;
&lt;li&gt;采用三层架构：卷积、下采样、非线性激活函数(tanh, sigmoid)，多层神经网络(MLP)作为最后的分类器&lt;/li&gt;
&lt;li&gt;后续的CNN架构大多基于LeNet5的这些特性，然而由于当时硬件计算能力限制，后续很长时间神经网络没有发展&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;AlexNet(2012): 赢的2012ImageNet冠军，从LeNet5的5层增加到7层&lt;ul&gt;
&lt;li&gt;使用ReLU作为激活函数，降低计算量&lt;/li&gt;
&lt;li&gt;引入Dropout防止过拟合&lt;/li&gt;
&lt;li&gt;引入Max-Pooling技术&lt;/li&gt;
&lt;li&gt;使用双GPU，分group卷积，显著减少训练时间
    
    </summary>
    
      <category term="machine-learning" scheme="http://tcye.github.io/categories/machine-learning/"/>
    
    
  </entry>
  
  <entry>
    <title>深度学习入坑指南</title>
    <link href="http://tcye.github.io/posts/a30f8eef/"/>
    <id>http://tcye.github.io/posts/a30f8eef/</id>
    <published>2017-09-25T08:30:35.000Z</published>
    <updated>2019-10-17T07:07:02.973Z</updated>
    
    <content type="html"><![CDATA[<p>硕士期间也是做传统视觉相关的研究，但自己并没有选择继续读博，而是选择去了网易游戏工作。工作这两年，一来对做游戏逻辑感到枯燥厌恶，二来也在媒体的推波助澜下见识了深度学习横扫计算机视觉界的威风，很多以前看似很难的视觉任务，突然都变得简单，所以，摩拳擦掌又想回去做计算机视觉。进入BIGO做了一段时间，发现自己做的还不错，深度学习入门的很快，所以在这里记录下自己的入坑经历，希望可以帮到也有类似想法的同学吧。</p><a id="more"></a><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>2017年8月28日，我正式入职Bigo Live，离开曾经奋斗了两年的网易游戏，从零开始，转行做了一名机器学习算法工程师。至于为什么我会突然转行去做机器学习，我在<a href="https://tcye.github.io/about/"><strong>这里</strong></a>有写到。总之，2017年对于我是动荡的一年，结了婚（哈哈，从此家里多了一只小燕子），买了房，然后还换了工作，这所有一切都发生在短短几个月内。其实结婚买房前，我都是想好好继续在网易游戏干下去的，毕竟收入不错也还算稳定，工作室有着极其活跃的氛围和宽松简单的人际关系（虽然加班有点多）。然而了解我的人就知道，我从来不是一个安于现状的人，在6月份的某一天，我就决定了，我要转行去做AI！</p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>其实对于机器学习我是有一定基础的，然而从毕业开始算，已时隔两年，期间做了两年3D MMO手游，可想而知，即使我能把知识全放进一块移动硬盘保存起来，现在想找到那块移动硬盘，恐怕也有点费力了。。。</p><p>第一步，数学基础。复习了一遍线性代数，教材<a href="http://math.mit.edu/~gs/linearalgebra/" target="_blank" rel="noopener">Introduction to Linear Algebra</a>，因为上研时读过这本书，所以捡起来比较快，我大概花了一个周末两天时间过了一遍线代。然后就没有了，其实对于机器学习，有线代基础就足以入门了，其他数学知识并非必须，比如概率论，我认为只是对于机器学习理论的一种解释而已，如果你只是把机器学习当做一个拟合已有数据的优化问题，那么暂时不管概率论也完全没问题，更何况有些模型，比如神经网络，本来也没有一个概率上的解释。</p><p>第二步，机器学习基础。使用了李航的<a href="https://book.douban.com/subject/10590856/" target="_blank" rel="noopener">统计学习方法</a>，同时配合周志华的<a href="https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/MLbook2016.htm" target="_blank" rel="noopener">西瓜书</a>。注意：《统计学习方法》的第一章非常重要！一定要仔细阅读，确保自己理解到位了，尤其是统计学习三要素，这是后面所有模型的基础。然后要重点理解线性回归、逻辑斯蒂回归、SVM，并尝试梳理三者的联系和关系！一旦这一步做到位了，对于后面神经网络的学习将会大有裨益。</p><p>第三步，深度学习。真的，这一步啥都不要看，如果你没有任何基础的话，老老实实从stanford的<a href="http://cs231n.stanford.edu/syllabus.html" target="_blank" rel="noopener">cs231n</a>的视频一路看下来即可。这一步其实我走了很多弯路，最后才发现，cs231n才是良心啊！有热心朋友已经从墙外把视频搬到了<a href="https://www.bilibili.com/video/av13260183/?from=search&amp;seid=3316462347725890303" target="_blank" rel="noopener">哔哩哔哩</a>，大家认真学习即可！真的，看了这个还学不会，你来打我！（真的没想到自己会有一天在B站搞学习！）</p><h2 id="行动"><a href="#行动" class="headerlink" title="行动"></a>行动</h2><p>我认为学习任何事情，都要有实际应用场景，并不断操练才可以，所以不管怎样，我必须先找一份机器学习的工作做起来，否则永远也只是纸上谈兵！广州的互联网氛围还是没有北京好啊，看了下脉脉，在招机器学习岗位的单位大概只有这么几家：腾讯微信、阿里UC、欢聚时代（YY）、图谱科技。</p><p>微信当时正成立了搜索部门，于是找了个中科院的师兄帮忙内推了一下，结果准备不充分，而且他们可能更需要NLP相关的，说研究生的图像相关经历也聊不拢，面了两面就挂掉了。。。</p><p>阿里UC有推荐相关的岗位，然而并没有人帮忙内推，投了官网简历了无音讯。。。</p><p>图谱科技主要做深度学习鉴黄相关的，理论上应该蛮对口，然而并不认识人。。。去拉钩投了他们的一份简历，过了大概一两周才给了回复，不是让我去面试，是让我先做一份在线笔试题。。。由于当时已经差不多快拿到BIGO的Offer了，所以我就没有尝试了。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>其实转行最难的一步是有一个可以接纳你的地方。如果不是BIGO收留我，恐怕也会很难成功转行。最近这段时间的变动暂时记录到这里，希望以后能有更多进步吧，同时总结更多算法方面的经验到博客中。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;硕士期间也是做传统视觉相关的研究，但自己并没有选择继续读博，而是选择去了网易游戏
工作。工作这两年，一来对做游戏逻辑感到枯燥厌恶，二来也在媒体的推波助澜下见识了
深度学习横扫计算机视觉界的威风，很多以前看似很难的视觉任务，突然都变得简单，所以，
摩拳擦掌又想回去做计算机视觉。进入BIGO做了一段时间，发现自己做的还不错，深度学习
入门的很快，所以在这里记录下自己的入坑经历，希望可以帮到也有类似想法的同学吧。&lt;/p&gt;
    
    </summary>
    
      <category term="life" scheme="http://tcye.github.io/categories/life/"/>
    
    
  </entry>
  
  <entry>
    <title>常用Markdown语法备忘</title>
    <link href="http://tcye.github.io/posts/a4f440d3/"/>
    <id>http://tcye.github.io/posts/a4f440d3/</id>
    <published>2017-05-15T05:30:35.000Z</published>
    <updated>2019-10-17T07:07:02.973Z</updated>
    
    <content type="html"><![CDATA[<h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>行间</p><p>$$a = b^2$$</p><p>行内公式\(a = b^2\)</p><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span>, <span class="keyword">char</span>**)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a id="more"></a><h3 id="文本居中引用"><a href="#文本居中引用" class="headerlink" title="文本居中引用"></a>文本居中引用</h3><blockquote class="blockquote-center"><p>人的一切痛苦，本质上都是对自己无能的愤怒。</p><p><strong>王小波</strong></p></blockquote><h3 id="标注"><a href="#标注" class="headerlink" title="标注"></a>标注</h3><div class="note default">            <p>Content (md partial supported) </p>          </div><div class="note primary">            <p>Content (md partial supported) </p>          </div><div class="note success">            <p>Content (md partial supported) </p>          </div><div class="note info">            <p>Content (md partial supported) </p>          </div><div class="note warning">            <p>Content (md partial supported) </p>          </div><div class="note danger">            <p>Content (md partial supported) </p>          </div><h3 id="手动分割显示更多"><a href="#手动分割显示更多" class="headerlink" title="手动分割显示更多"></a>手动分割显示更多</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- more --&gt;</span><br></pre></td></tr></table></figure><h3 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[Hexo](https://hexo.io/)</span><br></pre></td></tr></table></figure><p><a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a></p><h3 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![头像](/images/avatar.jpg)</span><br></pre></td></tr></table></figure><p><img src="/images/avatar.jpg" alt="头像"></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;公式&quot;&gt;&lt;a href=&quot;#公式&quot; class=&quot;headerlink&quot; title=&quot;公式&quot;&gt;&lt;/a&gt;公式&lt;/h3&gt;&lt;p&gt;行间&lt;/p&gt;
&lt;p&gt;$$a = b^2$$&lt;/p&gt;
&lt;p&gt;行内公式\(a = b^2\)&lt;/p&gt;
&lt;h3 id=&quot;代码&quot;&gt;&lt;a href=&quot;#代码&quot; class=&quot;headerlink&quot; title=&quot;代码&quot;&gt;&lt;/a&gt;代码&lt;/h3&gt;&lt;figure class=&quot;highlight c++&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;include&lt;/span&gt;&lt;span class=&quot;meta-string&quot;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;keyword&quot;&gt;char&lt;/span&gt;**)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="misc" scheme="http://tcye.github.io/categories/misc/"/>
    
    
      <category term="markdown" scheme="http://tcye.github.io/tags/markdown/"/>
    
  </entry>
  
  <entry>
    <title>开发环境配置</title>
    <link href="http://tcye.github.io/posts/58d09dd7/"/>
    <id>http://tcye.github.io/posts/58d09dd7/</id>
    <published>2017-05-15T05:30:35.000Z</published>
    <updated>2019-10-17T07:07:02.973Z</updated>
    
    <content type="html"><![CDATA[<h3 id="文件夹配置"><a href="#文件夹配置" class="headerlink" title="文件夹配置"></a>文件夹配置</h3><p>干掉默认的几个文件夹，相关配置/etc/xdg/user-dirs.defaults，~/.config/user-dirs.dirs，只需修改个人文件即可，参考配置<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">XDG_DESKTOP_DIR=<span class="string">"<span class="variable">$HOME</span>/"</span></span><br><span class="line">XDG_DOWNLOAD_DIR=<span class="string">"<span class="variable">$HOME</span>/"</span></span><br><span class="line">XDG_TEMPLATES_DIR=<span class="string">"<span class="variable">$HOME</span>/"</span></span><br><span class="line">XDG_PUBLICSHARE_DIR=<span class="string">"<span class="variable">$HOME</span>/"</span></span><br><span class="line">XDG_DOCUMENTS_DIR=<span class="string">"<span class="variable">$HOME</span>/"</span></span><br><span class="line">XDG_MUSIC_DIR=<span class="string">"<span class="variable">$HOME</span>/"</span></span><br><span class="line">XDG_PICTURES_DIR=<span class="string">"<span class="variable">$HOME</span>/"</span></span><br><span class="line">XDG_VIDEOS_DIR=<span class="string">"<span class="variable">$HOME</span>/"</span></span><br></pre></td></tr></table></figure></p><p>然后删除默认文件夹即可，建立常用文件夹<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~ &amp;&amp; rm * -rf &amp;&amp; mkdir data downloads repo workspace</span><br></pre></td></tr></table></figure></p><h3 id="NVIDIA-CUDA"><a href="#NVIDIA-CUDA" class="headerlink" title="NVIDIA CUDA"></a>NVIDIA CUDA</h3><ol><li>安装显卡驱动</li><li>安装cuda<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm stop</span><br><span class="line">sudo ./NVIDIA.xxx.run --no-opengl-files</span><br><span class="line">sudo ./cuda.xxx.sh --no-opengl-libs</span><br></pre></td></tr></table></figure></li></ol><h3 id="软件配置"><a href="#软件配置" class="headerlink" title="软件配置"></a>软件配置</h3><ol><li><p>CLion, PyCharm: </p><ul><li>下载后分别解压到/opt/clion /opt/pycharm</li><li><p>Help-&gt;Edit Custom Options，加入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-javaagent:/usr/share/java/jayatanaag.jar</span><br></pre></td></tr></table></figure></li><li><p>Tools-&gt;Create Desktop Entry</p></li><li>licence: 账号密码见网易云笔记</li></ul></li><li><p>QtCreator:</p><ul><li>编辑 /usr/share/applications/DigiaQt-qtcreator-community.desktop<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exec=env XDG_CURRENT_DESKTOP=GNOME /opt/Qt5.10.0/Tools/QtCreator/bin/qtcreator</span><br></pre></td></tr></table></figure></li></ul></li><li><p>VMWare Player</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vmplayer.showChrome = &quot;FALSE&quot;</span><br></pre></td></tr></table></figure></li><li><p>l2tp vpn</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install network-manager-l2tp-gnome</span><br></pre></td></tr></table></figure></li><li><p>vim &amp;&amp; font &amp;&amp; ssh</p><ul><li>参考 <a href="https://github.com/tcye/editor_config" target="_blank" rel="noopener">https://github.com/tcye/editor_config</a></li></ul></li></ol><h3 id="其他需要安装的软件"><a href="#其他需要安装的软件" class="headerlink" title="其他需要安装的软件"></a>其他需要安装的软件</h3><ul><li>SecureCRT, SecureFX</li><li>网易云音乐，搜狗输入法</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;文件夹配置&quot;&gt;&lt;a href=&quot;#文件夹配置&quot; class=&quot;headerlink&quot; title=&quot;文件夹配置&quot;&gt;&lt;/a&gt;文件夹配置&lt;/h3&gt;&lt;p&gt;干掉默认的几个文件夹，相关配置/etc/xdg/user-dirs.defaults，~/.config/user-
      
    
    </summary>
    
      <category term="misc" scheme="http://tcye.github.io/categories/misc/"/>
    
    
      <category term="配置" scheme="http://tcye.github.io/tags/%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
</feed>
